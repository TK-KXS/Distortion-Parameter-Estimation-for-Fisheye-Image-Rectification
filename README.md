# Abstract

The widespread use of fisheye cameras in areas like autonomous driving and surveillance has highlighted the need for effective image rectification methods to address the significant distortions caused by these lenses. While deep learning has shown promise in improving rectification accuracy, many existing studies lack clarity, failing to provide model weights, codes, and detailed rectification processes, which complicates replication. This project uses a deep neural network to predict distortion parameters and the rectification program to rectify both real and synthesised fisheye images. The framework consists of three key components: dataset synthesis, model training and validation, and image rectification and evaluation. Two deep learning architectures (AlexNet and Vision Transformer) and three training schemes were explored. AlexNet delivered the best performance, particularly under Classification and Classification + Regression schemes. Moreover, the rectification program effectively corrected real fisheye images, surpassing existing methods in both image quality and quantitative metrics. This work addresses research gaps by providing comprehensive model and rectification program details and a replicable framework, laying the groundwork for future advancements in fisheye image rectification.


![image description](./Instruction1.png)
