{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from torchvision.models import alexnet\n",
    "from torch.optim import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.rcParams['figure.dpi'] = 300\n",
    "sns.set_theme()\n",
    "sns.set_style(\"ticks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inputs\n",
    "\n",
    "df_train_path = 'df_train.csv'\n",
    "df_val_path  = 'df_val.csv'\n",
    "df_test_path  = 'df_test.csv'\n",
    "distort_img_path = 'distorted_crosswalk_images_crop'\n",
    "num_epochs_for_today = 10\n",
    "checkpoint_path = 'AlexNet_cuda_weights/AlexNet_Reg_Checkpoint.pth.tar'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_full = pd.read_csv(df_train_path)\n",
    "df_val_full = pd.read_csv(df_val_path)\n",
    "df_test_full = pd.read_csv(df_test_path)\n",
    "\n",
    "df_train = df_train_full[[\"id2\",\"k\"]]\n",
    "df_val = df_val_full[[\"id2\",\"k\"]]\n",
    "df_test = df_test_full[[\"id2\",\"k\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Data Transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Create the Custom Dataset Class\n",
    "class CrosswayDataset(Dataset):\n",
    "    def __init__(self, dataframe, root_dir, transform=None):\n",
    "        self.dataframe = dataframe\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.root_dir, str(self.dataframe.iloc[idx, 0]) + '.jpg')\n",
    "        image = Image.open(img_name).convert('RGB')\n",
    "        k_gt = self.dataframe.iloc[idx, 1] \n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, k_gt\n",
    "    \n",
    "def load_checkpoint(filename):\n",
    "    checkpoint = torch.load(filename)\n",
    "    model.load_state_dict(checkpoint['model_state'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state'])\n",
    "    start_epoch = checkpoint['epoch']\n",
    "    return start_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Dataset Objects and DataLoaders\n",
    "train_dataset = CrosswayDataset(dataframe=df_train, root_dir=distort_img_path, transform=transform)\n",
    "val_dataset = CrosswayDataset(dataframe=df_val, root_dir=distort_img_path, transform=transform)\n",
    "test_dataset = CrosswayDataset(dataframe=df_test, root_dir=distort_img_path, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Begin training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Resuming training from epoch 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [26/30] Training Loss: 2.7095536089653578e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [26/30] Validation Loss: 9.306827857426441e-10\n",
      "Checkpoint saved at epoch 26\n",
      "Model saved to AlexNet_weights/reg/alexnet_reg_epoch_26.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [27/30] Training Loss: 2.316914962108285e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [27/30] Validation Loss: 2.627140891004526e-09\n",
      "Checkpoint saved at epoch 27\n",
      "Model saved to AlexNet_weights/reg/alexnet_reg_epoch_27.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [28/30] Training Loss: 2.0363378996133252e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [28/30] Validation Loss: 1.1511624263299828e-08\n",
      "Checkpoint saved at epoch 28\n",
      "Model saved to AlexNet_weights/reg/alexnet_reg_epoch_28.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [29/30] Training Loss: 1.798281058302999e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [29/30] Validation Loss: 1.6408434716003677e-09\n",
      "Checkpoint saved at epoch 29\n",
      "Model saved to AlexNet_weights/reg/alexnet_reg_epoch_29.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [30/30] Training Loss: 1.5409533868354587e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [30/30] Validation Loss: 1.1308701296430015e-08\n",
      "Checkpoint saved at epoch 30\n",
      "Model saved to AlexNet_weights/reg/alexnet_reg_epoch_30.pth\n"
     ]
    }
   ],
   "source": [
    "# Load the pretrained AlexNet model\n",
    "model = alexnet(pretrained=True)\n",
    "\n",
    "# Modify the classifier to output a single value for regression\n",
    "model.classifier[-1] = nn.Linear(in_features=4096, out_features=1)\n",
    "\n",
    "# Move the model to the GPU if available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")  # Add this line to check if GPU is being used\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "# Loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = Adam(model.parameters(), lr=1e-6)\n",
    "\n",
    "# Load checkpoint if it exists\n",
    "if os.path.exists(checkpoint_path):\n",
    "    start_epoch = load_checkpoint(checkpoint_path)\n",
    "    print(f\"Resuming training from epoch {start_epoch + 1}\")\n",
    "else:\n",
    "    start_epoch = 0\n",
    "\n",
    "# Training loop\n",
    "num_epochs = start_epoch + num_epochs_for_today\n",
    "\n",
    "training_loss_list = []\n",
    "validation_loss_list = []\n",
    "\n",
    "for epoch in range(start_epoch, num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    # Training phase\n",
    "    progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Training]\", leave=False)\n",
    "    for images, k_gt in progress_bar:\n",
    "        images = images.to(device)\n",
    "        k_gt = k_gt.to(device).float().view(-1, 1)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, k_gt)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        \n",
    "        # Update the progress bar\n",
    "        progress_bar.set_postfix(loss=loss.item())\n",
    "\n",
    "    epoch_loss = running_loss / len(train_dataset)\n",
    "    training_loss_list.append(epoch_loss)\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}] Training Loss: {epoch_loss}')\n",
    "    \n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        progress_bar = tqdm(val_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Validation]\", leave=False)\n",
    "        for images, k_gt in progress_bar:\n",
    "            images = images.to(device)\n",
    "            k_gt = k_gt.to(device).float().view(-1, 1)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, k_gt)\n",
    "\n",
    "            val_loss += loss.item() * images.size(0)\n",
    "            \n",
    "            # Update the progress bar\n",
    "            progress_bar.set_postfix(loss=loss.item())\n",
    "    \n",
    "    val_loss /= len(val_dataset)\n",
    "    validation_loss_list.append(val_loss)\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}] Validation Loss: {val_loss}')\n",
    "    \n",
    "    # Save the model and optimizer states for this epoch\n",
    "    checkpoint = {\n",
    "        'epoch': epoch + 1,\n",
    "        'model_state': model.state_dict(),\n",
    "        'optimizer_state': optimizer.state_dict()\n",
    "    }\n",
    "    torch.save(checkpoint, checkpoint_path)\n",
    "    print(f\"Checkpoint saved at epoch {epoch+1}\")\n",
    "\n",
    "    # Save the model weights separately for this epoch\n",
    "    model_save_path = os.path.join(f'AlexNet_cuda_weights/reg/alexnet_reg_epoch_{epoch}.pth') #############################################\n",
    "    torch.save(model.state_dict(), model_save_path)\n",
    "    print(f'Model saved to {model_save_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2.7095536089653578e-08,\n",
       " 2.316914962108285e-08,\n",
       " 2.0363378996133252e-08,\n",
       " 1.798281058302999e-08,\n",
       " 1.5409533868354587e-08]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_loss_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[9.306827857426441e-10,\n",
       " 2.627140891004526e-09,\n",
       " 1.1511624263299828e-08,\n",
       " 1.6408434716003677e-09,\n",
       " 1.1308701296430015e-08]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_loss_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib64/python3.7/site-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "/usr/local/lib64/python3.7/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AlexNet(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.5, inplace=False)\n",
       "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): Linear(in_features=4096, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Load the pretrained AlexNet model\n",
    "model = alexnet(pretrained=True)\n",
    "\n",
    "# Modify the classifier to output 18 classes\n",
    "model.classifier[-1] = nn.Linear(in_features=4096, out_features=1)\n",
    "\n",
    "# Load the model weights\n",
    "model_path = 'AlexNet_cuda_weights/reg/alexnet_reg_epoch_14.pth'  ############# Select your trained model weights\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Testing on 1 image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the image transformations (same as used during training)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Function to perform inference and get probabilities\n",
    "def predict_image(image_path):\n",
    "    # Load and preprocess the image\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    image = transform(image).unsqueeze(0)  # Add batch dimension\n",
    "    image = image.to(device)\n",
    "\n",
    "    # Perform inference\n",
    "    with torch.no_grad():\n",
    "        output = model(image)\n",
    "\n",
    "    # Get the prediction (regression output)\n",
    "    prediction = output.item()\n",
    "\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted k: 5.65106e-05\n",
      "Ground truth k: 7.77023e-05\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "test_img_path = os.path.join(distort_img_path, str(df_test.iloc[0, 0]) + '.jpg')\n",
    "prediction = predict_image(test_img_path)\n",
    "prediction = \"{:.5e}\".format(prediction)\n",
    "\n",
    "ground_truth = df_test.iloc[0,1]\n",
    "ground_truth = \"{:.5e}\".format(ground_truth)\n",
    "\n",
    "print(f'Predicted k: {prediction}')\n",
    "print(f'Ground truth k: {ground_truth}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Testing on `test_loader`, Classification Report, Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming the model is already loaded and test_dataset is defined\n",
    "model.eval()\n",
    "\n",
    "# DataLoader for the test dataset\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Initialize lists to store true labels and predictions\n",
    "all_k_gts = []\n",
    "all_k_preds = []\n",
    "\n",
    "# Inference on the test dataset\n",
    "with torch.no_grad():\n",
    "    for images, k_gt in test_loader:\n",
    "        images = images.to(device)\n",
    "        k_gts = k_gt.to(device)\n",
    "\n",
    "        k_preds = model(images)\n",
    "\n",
    "        all_k_gts.extend(k_gt.cpu().numpy())\n",
    "        all_k_preds.extend(k_preds.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert lists to numpy arrays\n",
    "all_k_gts = np.array(all_k_gts)\n",
    "all_k_preds = np.array(all_k_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id2</th>\n",
       "      <th>k</th>\n",
       "      <th>k_preds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2066703</td>\n",
       "      <td>0.000078</td>\n",
       "      <td>0.000057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2074905</td>\n",
       "      <td>0.000062</td>\n",
       "      <td>0.000057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022038</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>0.000057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2060686</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2004094</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.000057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9895</th>\n",
       "      <td>2021815</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.000057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9896</th>\n",
       "      <td>2065463</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.000057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9897</th>\n",
       "      <td>2011739</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9898</th>\n",
       "      <td>2018046</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.000057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9899</th>\n",
       "      <td>2071075</td>\n",
       "      <td>0.000093</td>\n",
       "      <td>0.000057</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9900 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id2         k   k_preds\n",
       "0     2066703  0.000078  0.000057\n",
       "1     2074905  0.000062  0.000057\n",
       "2     2022038  0.000061  0.000057\n",
       "3     2060686  0.000100  0.000057\n",
       "4     2004094  0.000036  0.000057\n",
       "...       ...       ...       ...\n",
       "9895  2021815  0.000037  0.000057\n",
       "9896  2065463  0.000025  0.000057\n",
       "9897  2011739  0.000058  0.000057\n",
       "9898  2018046  0.000030  0.000057\n",
       "9899  2071075  0.000093  0.000057\n",
       "\n",
       "[9900 rows x 3 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_report = df_test.copy(deep=True)\n",
    "df_test_report[\"k_preds\"] = all_k_preds\n",
    "df_test_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% Mean Absolute Error: 190.49%\n"
     ]
    }
   ],
   "source": [
    "percent_mae = np.mean(100 * np.abs(all_k_preds - all_k_gts) / all_k_gts)\n",
    "\n",
    "print(f\"% Mean Absolute Error: {percent_mae:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): 2.5751273412329176e-05\n",
      "Root Mean Squared Error (RMSE): 3.0787421069709145e-05\n",
      "R-squared (R²): -0.1601533067405283\n"
     ]
    }
   ],
   "source": [
    "# Mean Absolute Error\n",
    "mae = mean_absolute_error(all_k_gts, all_k_preds)\n",
    "\n",
    "# Root Mean Squared Error\n",
    "rmse = np.sqrt(mean_squared_error(all_k_gts, all_k_preds))\n",
    "\n",
    "# R-squared\n",
    "r2 = r2_score(all_k_gts, all_k_preds)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n",
    "print(f\"R-squared (R²): {r2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# All at once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the image transformations (same as used during training)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Function to perform inference and get probabilities\n",
    "def predict_image(image_path):\n",
    "    # Load and preprocess the image\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    image = transform(image).unsqueeze(0)  # Add batch dimension\n",
    "    image = image.to(device)\n",
    "\n",
    "    # Perform inference\n",
    "    with torch.no_grad():\n",
    "        output = model(image)\n",
    "\n",
    "    # Get the prediction (regression output)\n",
    "    prediction = output.item()\n",
    "\n",
    "    return prediction\n",
    "\n",
    "def all_at_once(model_path):\n",
    "    \n",
    "    # Define the device\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    # Load the pretrained AlexNet model\n",
    "    model = alexnet(pretrained=True)\n",
    "\n",
    "    # Modify the classifier to output 18 classes\n",
    "    model.classifier[-1] = nn.Linear(in_features=4096, out_features=1)\n",
    "\n",
    "    # Load the model weights\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    # Initialize lists to store true labels and predictions\n",
    "    all_k_gts = []\n",
    "    all_k_preds = []\n",
    "\n",
    "    # Inference on the test dataset\n",
    "    with torch.no_grad():\n",
    "        for images, k_gt in test_loader:\n",
    "            images = images.to(device)\n",
    "            k_gts = k_gt.to(device)\n",
    "\n",
    "            k_preds = model(images)\n",
    "\n",
    "            all_k_gts.extend(k_gt.cpu().numpy())\n",
    "            all_k_preds.extend(k_preds.cpu().numpy())\n",
    "            \n",
    "    # Convert lists to numpy arrays\n",
    "    all_k_gts = np.array(all_k_gts)\n",
    "    all_k_preds = np.array(all_k_preds)\n",
    "    df_test_report = df_test.copy(deep=True)\n",
    "    df_test_report[\"k_preds\"] = all_k_preds\n",
    "    average_percentage_error = np.mean(100 * np.abs(all_k_preds - all_k_gts) / all_k_gts)\n",
    "    return round(average_percentage_error,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Epoch 16: average_percentage_error = 115.3778\n",
      "Using device: cuda\n",
      "Epoch 17: average_percentage_error = 667.0475\n",
      "Using device: cuda\n",
      "Epoch 18: average_percentage_error = 138.4431\n",
      "Using device: cuda\n",
      "Epoch 19: average_percentage_error = 476.3731\n",
      "Using device: cuda\n",
      "Epoch 20: average_percentage_error = 156.2892\n",
      "Using device: cuda\n",
      "Epoch 21: average_percentage_error = 1017.9783\n",
      "Using device: cuda\n",
      "Epoch 22: average_percentage_error = 484.4738\n",
      "Using device: cuda\n",
      "Epoch 23: average_percentage_error = 314.8451\n",
      "Using device: cuda\n",
      "Epoch 24: average_percentage_error = 625.2054\n",
      "Using device: cuda\n",
      "Epoch 25: average_percentage_error = 138.0645\n",
      "Using device: cuda\n",
      "Epoch 26: average_percentage_error = 202.4918\n",
      "Using device: cuda\n",
      "Epoch 27: average_percentage_error = 333.7178\n",
      "Using device: cuda\n",
      "Epoch 28: average_percentage_error = 616.6683\n",
      "Using device: cuda\n",
      "Epoch 29: average_percentage_error = 273.45\n",
      "Using device: cuda\n",
      "Epoch 30: average_percentage_error = 612.038\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[115.3778,\n",
       " 667.0475,\n",
       " 138.4431,\n",
       " 476.3731,\n",
       " 156.2892,\n",
       " 1017.9783,\n",
       " 484.4738,\n",
       " 314.8451,\n",
       " 625.2054,\n",
       " 138.0645,\n",
       " 202.4918,\n",
       " 333.7178,\n",
       " 616.6683,\n",
       " 273.45,\n",
       " 612.038]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_percentage_error_list = []\n",
    "\n",
    "for i in range(16,31):\n",
    "    model_path = f\"AlexNet_cuda_weights/reg/alexnet_reg_epoch_{i}.pth\"\n",
    "    average_percentage_error = all_at_once(model_path)\n",
    "    average_percentage_error_list.append(average_percentage_error)\n",
    "    print(f\"Epoch {i}: average_percentage_error = {average_percentage_error}\")\n",
    "\n",
    "average_percentage_error_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
